---
layout: project
urltitle: "NSF Language Science Workshop"
title: "NSF Language Science Workshop"
categories: workshop, 2024
permalink: /
bibtex: true
paper: true
acknowledgements: ""
---

<br />

<!-- Motivation -->
<div class="row" id="home">
<div class="col-xs-12">
<p>
Large language models are remarkably successful as technological
tools, and pose challenges and opportunities for the scientific study
of natural language in the human mind and brain. This workshop
presents <b>talks, commentary, and discussion</b> dedicated to the
following three themes: 
<ul>
<li><b>What insights do large language models provide for the study of human language?</b></li>
<li><b>What insights does the study of human language provide for large language model development?</b></li>
<li><b>What key future scientific opportunities lie at the interface between the study of human language and large language model development?</b></li>
</ul>
</p><p>
<!-- <a href="https://nsf.zoomgov.com/webinar/register/WN_sNu3mKvZSdadFvccnv_MJQ" target="_blank">
<button><b>Register here</b></button></a>
to join us via Zoom on <b>May 13 and 14</b> to learn more about recent advances, 
open questions, challenges, and opportunities in this rapidly advancing landscape! 
Online participants will have the opportunity to pose questions and discuss with each other, 
which will form part of the collected materials to inform a subsequent
written report to help guide the future of research in language science.
</p><p>
Talks will be recorded and, following
the workshop, hosted for public access (link coming soon). -->
<a href="https://www.youtube.com/playlist?list=PLaTQnvGIKBXqo8Lcl82KptxY6zJMpGmts" target="_blank">
<button><b>Click here</b></button></a>
to watch the workshop recordings! 
<br>
<br>
Specific talks can also be accessed via the 📹 icons next to the scheduled speakers.
</p>
</div>
</div>

<hr />

<!-- Schedule -->
<div class="row" id="schedule">
  <div class="col-xs-12">
    <h2>Schedule (Eastern Time; precise times subject to revision)</h2>
  </div>
</div>

<div class="row">
<div class="col-xs-12">
<p>

<br />

<b>Monday, May 13:</b>

<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{border-color:black;border-style:solid;border-width:0px;font-family:Arial, sans-serif;font-size:14px;
  overflow:hidden;padding:10px 5px;word-break:normal;}
.tg th{border-color:black;border-style:solid;border-width:0px;font-family:Arial, sans-serif;font-size:14px;
  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top}
</style>
<!-- <thead> -->
<!--   <tr> -->
<!--     <th class="tg-0lax">9:00am</th> -->
<!--     <th class="tg-0lax">Introductory remarks</th> -->
<!--   </tr> -->
<!-- </thead> -->
<table class="tg">
<tbody>
  <tr>
    <td class="tg-0lax"><b>9:00–9:10am</b></td>
    <td class="tg-0lax"><b>Opening remarks by NSF leadership</b></td>
  </tr>
  <tr>
    <td class="tg-0lax"><b>9:10–9:30am</b></td>
    <td class="tg-0lax"><b>Introductory remarks and orientation by
    workshop organizers</b></td>
  </tr>
  <tr>
    <td class="tg-0lax"><b>9:30am–12:30pm</b></td>
    <td class="tg-0lax"><b>Theme 1: What insights do large language models provide for the study of human language?</b></td>
  </tr>
  <tr>
    <td class="tg-0lax">9:30–9:35am</td>
    <td class="tg-0lax">
    <a href="https://cogandbrainlab.web.illinois.edu/">Kara Federmeier</a>: Introductory remarks for Theme 1
    </td>
  </tr>
  <tr>
    <td class="tg-0lax">9:35–9:55am</td>
    <td class="tg-0lax">
    <a href="https://pages.ucsd.edu/~bkbergen/">Benjamin Bergen</a>: 
    <a href="#bergen">Large Language Models as distributional baselines for human language processing research</a>
    <a href="https://www.youtube.com/watch?v=vTjdO3bkJwE&list=PLaTQnvGIKBXqo8Lcl82KptxY6zJMpGmts">📹</a>
    </td>
  </tr>
  <tr>
    <td class="tg-0lax">9:55–10:15am</td>
    <td class="tg-0lax">
    <a href="https://www.cs.cmu.edu/~lwehbe/">Leila Wehbe</a>: <a href="#wehbe">Learning representations of complex meaning in the human brain</a>
    <a href="https://www.youtube.com/watch?v=hnPLapmCJwI&list=PLaTQnvGIKBXqo8Lcl82KptxY6zJMpGmts">📹</a>
    </td>
  </tr>
  <tr>
    <td class="tg-0lax">10:15–10:35am</td>
    <td class="tg-0lax">
    <a href="https://miriamhavin.wixsite.com/interactlab/blank-3">Ariel Goldstein</a>: <a href="#goldstein">Deep modeling as (more) than (just) cognitive framework</a>
    <a href="https://www.youtube.com/watch?v=Q7VG08VYqt4&list=PLaTQnvGIKBXqo8Lcl82KptxY6zJMpGmts">📹</a>
    </td>
  </tr>
  <tr>
    <td class="tg-0lax">10:35–10:55am</td>
    <td class="tg-0lax">
    <a href="https://baulab.info/">David Bau</a>: <a href="#bau">Locating neural functions and facts</a>
    <a href="https://www.youtube.com/watch?v=Pj72GJbW3Os&list=PLaTQnvGIKBXqo8Lcl82KptxY6zJMpGmts">📹</a>
    </td>
  </tr>
  <tr>
    <td class="tg-0lax">10:55–11:10am</td>
    <td class="tg-0lax">Break</td>
  </tr>  
  <tr>
    <td class="tg-0lax">11:10–11:50am</td>
    <td class="tg-0lax"><b>Moderated commentary session</b> with 
    <a href="https://staff.fnwi.uva.nl/r.fernandezrovira/">Raquel
    Fernandez</a>, <a href="https://tallinzen.net/">Tal Linzen</a>,
    and <a href="http://languagestats.com/jonwillits/about.html">Jon Willits</a>
    <a href="https://www.youtube.com/watch?v=Pz1Gx1VlS3g&list=PLaTQnvGIKBXqo8Lcl82KptxY6zJMpGmts">📹</a>
    </td>
  </tr>  
  <tr>
    <td class="tg-0lax">11:50am–12:30pm</td>
    <td class="tg-0lax"><b>Moderated panel discussion</b> including all
    speakers and commentators from the theme
    <a href="https://www.youtube.com/watch?v=3a-kbjQY9nw&list=PLaTQnvGIKBXqo8Lcl82KptxY6zJMpGmts">📹</a>
    </td>
  </tr>   
  <tr>
    <td class="tg-0lax"><b>12:30–2:00pm</b></td>
    <td class="tg-0lax"><b>Lunch Break</b></td>
  </tr>
    <tr>
    <td class="tg-0lax"><b>2:00–5:00pm</b></td>
    <td class="tg-0lax"><b>Theme 2: What insights does the study of human language provide for large language model development?</b></td>
  </tr>
  <tr>
    <td class="tg-0lax">2:00–2:05pm</td>
    <td class="tg-0lax">
    <a href="https://nlp.stanford.edu/~manning/">Christopher Manning</a>: Introductory remarks for Theme 2
    </td>
  </tr>
  <tr>
    <td class="tg-0lax">2:05–2:25pm</td>
    <td class="tg-0lax">
    <a href="https://rtmccoy.com/">Tom McCoy</a>: <a href="#mccoy">Using insights from linguistics to understand and guide Large Language Models</a>
    <a href="https://www.youtube.com/watch?v=0-xziFCzc8c&list=PLaTQnvGIKBXqo8Lcl82KptxY6zJMpGmts">📹</a>
    </td>
  </tr>
  <tr>
    <td class="tg-0lax">2:25–2:45pm</td>
    <td class="tg-0lax">
    <a href="https://najoung.kim/">Najoung Kim</a>: <a href="#kim">Linguistic tests as unit tests for AI systems</a>
    <a href="https://www.youtube.com/watch?v=nt5T_R837z0&list=PLaTQnvGIKBXqo8Lcl82KptxY6zJMpGmts">📹</a>
    </td>
  </tr>
  <tr>
    <td class="tg-0lax">2:45–3:05pm</td>
    <td class="tg-0lax">
    <a href="https://ai.meta.com/people/1396973444287406/adina-williams/">Adina Williams</a>: <a href="#williams">The shifting landscape of LM evaluation</a>
    <a href="https://www.youtube.com/watch?v=lGQPjaVaCCU&list=PLaTQnvGIKBXqo8Lcl82KptxY6zJMpGmts">📹</a>
    </td>
  </tr>
  <tr>
    <td class="tg-0lax">3:05–3:25pm</td>
    <td class="tg-0lax">
    <a href="https://rycolab.io/">Ryan Cotterell</a>: <a href="#cotterell">A formal perspective on language modeling</a>
    <a href="https://www.youtube.com/watch?v=9uETQL3jPes&list=PLaTQnvGIKBXqo8Lcl82KptxY6zJMpGmts">📹</a>
    </td>
  </tr>
  <tr>
    <td class="tg-0lax">3:25–3:40pm</td>
    <td class="tg-0lax">Break</td>
  </tr>  
  <tr>
    <td class="tg-0lax">3:40–4:20pm</td>
    <td class="tg-0lax"><b>Moderated commentary session</b> with commentators
    <a href="https://mahowak.github.io/">Kyle Mahowald</a>, <a
    href="https://annargrs.github.io/">Anna Rogers</a>, and <a href="https://psych.wisc.edu/staff/rogers-timothy-t/">Timothy Rogers</a>
    <a href="https://www.youtube.com/watch?v=KUxGMqAtN7s&list=PLaTQnvGIKBXqo8Lcl82KptxY6zJMpGmts">📹</a>
    </td>
  </tr>  
  <tr>
    <td class="tg-0lax">4:20–5:00pm</td>
    <td class="tg-0lax"><b>Moderated panel discussion</b> including all
    speakers and commentators from the theme
    <a href="https://www.youtube.com/watch?v=LwJ5-CtYAPc&list=PLaTQnvGIKBXqo8Lcl82KptxY6zJMpGmts">📹</a>
    </td>
  </tr>   
</tbody>
</table>

<br />

<b>Tuesday, May 14:</b>

<table class="tg">
<tbody>
  <tr>
    <td class="tg-0lax"><b>9:00am–12:00pm</b></td>
    <td class="tg-0lax"><b>Theme 3: What key future scientific opportunities lie at the interface between the study of human language and large language model development?</b></td>
  </tr>
  <tr>
    <td class="tg-0lax">9:00–9:05am</td>
    <td class="tg-0lax">
    <a href="https://www.mit.edu/~rplevy/">Roger Levy</a>: Introductory remarks for Theme 3
    </td>
  </tr>
  <tr>
    <td class="tg-0lax">9:05–9:25am</td>
    <td class="tg-0lax">
    <a href="https://psychology.princeton.edu/people/adele-goldberg">Adele Goldberg</a>: <a href="#goldberg">Compositionality in natural language and LLMs</a>
    <a href="https://www.youtube.com/watch?v=x48AiDPs7Zw&list=PLaTQnvGIKBXqo8Lcl82KptxY6zJMpGmts">📹</a>
    </td>
  </tr>
  <tr>
    <td class="tg-0lax">9:25–9:45am</td>
    <td class="tg-0lax">
    <a href="https://anna-ivanova.net/">Anna Ivanova</a>: <a href="#ivanova">Dissociating language and thought in Large Language Models</a>
    <a href="https://www.youtube.com/watch?v=mc3RA3APsD8&list=PLaTQnvGIKBXqo8Lcl82KptxY6zJMpGmts">📹</a>
    </td>
  </tr>
  <tr>
    <td class="tg-0lax">9:45–10:05am</td>
    <td class="tg-0lax">
    <a href="https://gbegus.github.io/">Gasper Begus</a>: <a href="#begus">Interpretability techniques for scientific discovery</a>
    <a href="https://www.youtube.com/watch?v=Di-nSQy2wak&list=PLaTQnvGIKBXqo8Lcl82KptxY6zJMpGmts">📹</a>
    </td>
  </tr>
  <tr>
    <td class="tg-0lax">10:05–10:25am</td>
    <td class="tg-0lax">
    <a href="https://www.cs.utexas.edu/~huth/">Alex Huth</a>: <a href="#huth">Mapping and decoding language representations in human cortex</a>
    <a href="https://www.youtube.com/watch?v=vUvXKqulCz4&list=PLaTQnvGIKBXqo8Lcl82KptxY6zJMpGmts">📹</a>
    </td>
  </tr>
  <tr>
    <td class="tg-0lax">10:25–10:40am</td>
    <td class="tg-0lax">Break</td>
  </tr>  
  <tr>
    <td class="tg-0lax">10:40–11:20am</td>
    <td class="tg-0lax"><b>Moderated commentary session</b> with
    commentators <a
    href="https://cs.gmu.edu/~antonis/author/antonios-anastasopoulos/">Antonios
    Anastasopoulus</a>, <a
    href="https://lauragwilliams.github.io/">Laura Gwilliams</a>, and
    <a href="https://ishita-dg.github.io/">Ishita Dasgupta</a>
    <a href="https://www.youtube.com/watch?v=11iZ1v3hNmo&list=PLaTQnvGIKBXqo8Lcl82KptxY6zJMpGmts">📹</a>
    </td>
  </tr>  
  <tr>
    <td class="tg-0lax">11:20am–12:00pm</td>
    <td class="tg-0lax"><b>Moderated panel discussion</b> including all
    speakers and commentators from the theme
    <a href="https://www.youtube.com/watch?v=fDa5GFXu9uA&list=PLaTQnvGIKBXqo8Lcl82KptxY6zJMpGmts">📹</a>
    </td>
  </tr>   
  <tr>
    <td class="tg-0lax"><b>12:00–1:30pm</b></td>
    <td class="tg-0lax"><b>Lunch Break</b></td>
  </tr>
    <tr>
    <td class="tg-0lax"><b>1:30–2:30pm</b></td>
    <td class="tg-0lax"><b>Summative talks by workshop organizers</b>
    <a href="https://cogandbrainlab.web.illinois.edu/">Kara
    Federmeier</a>, <a href="https://www.mit.edu/~rplevy/">Roger
    Levy</a>, and <a
    href="https://nlp.stanford.edu/~manning/">Christopher Manning</a>
    <a href="https://www.youtube.com/watch?v=Va1LZ-FNaoM&list=PLaTQnvGIKBXqo8Lcl82KptxY6zJMpGmts">📹</a>
    </td>
  </tr>
  <tr>
    <td class="tg-0lax"><b>2:30–2:45pm</b></td>
    <td class="tg-0lax"><b>Closing remarks by NSF leadership</b></td>
  </tr>
</tbody>
</table>

</p>
</div>
</div>

<hr />

<!-- Speakers -->
<div class="row" id="speakers">
  <div class="col-xs-12">
    <h2>Speakers</h2>
  </div>
</div>

<br/>

<div class="row">
  <div class="col-xs-6 col-lg-4">
    <a href="https://baulab.info/">
      <img class="people-pic" src="https://pbs.twimg.com/profile_images/1591452247417831424/nZA7ZHTB_400x400.jpg">
    </a>
    <div class="people-name">
      <a href="https://baulab.info/">David Bau</a>
      <h6>Northeastern University</h6>
    </div>
  </div>
  <div class="col-xs-6 col-lg-4">
    <a href="https://gbegus.github.io/">
      <img class="people-pic" src="https://i1.rgstatic.net/ii/profile.image/916616921505792-1595549912902_Q512/Gasper-Begus.jpg">
    </a>
    <div class="people-name">
      <a href="https://gbegus.github.io/">Gašper Beguš</a>
      <h6>UC Berkeley</h6>
    </div>
  </div>
  <div class="col-xs-6 col-lg-4">
    <a href="https://pages.ucsd.edu/~bkbergen/">
      <img class="people-pic" src="https://pages.ucsd.edu/~bkbergen/assets/img/team/team2.jpg">
    </a>
    <div class="people-name">
      <a href="https://pages.ucsd.edu/~bkbergen/">Benjamin Bergen</a>
      <h6>UC San Diego</h6>
    </div>
  </div>
  <div class="col-xs-6 col-lg-4">
    <a href="https://rycolab.io/">
      <img class="people-pic" src="https://reghorizon.com/wp-content/uploads/2021/09/2021-09_PCITURE_Ryan-Cotterell_400x400.jpg">
    </a>
    <div class="people-name">
      <a href="https://rycolab.io/">Ryan Cotterell</a>
      <h6>ETH Zürich</h6>
    </div>
  </div>
  <div class="col-xs-6 col-lg-4">
    <a href="https://cogandbrainlab.web.illinois.edu/">
      <img class="people-pic" src="https://i1.rgstatic.net/ii/profile.image/272344027496493-1441943284877_Q512/Kara-Federmeier.jpg">
    </a>
    <div class="people-name">
      <a href="https://cogandbrainlab.web.illinois.edu/">Kara Federmeier</a>
      <h6>University of Illinois</h6>
    </div>
  </div>
  <div class="col-xs-6 col-lg-4">
    <a href="https://psychology.princeton.edu/people/adele-goldberg">
      <img class="people-pic" src="https://scsb.mit.edu/wp-content/uploads/2023/01/Aeg.png">
    </a>
    <div class="people-name">
      <a href="https://psychology.princeton.edu/people/adele-goldberg">Adele Goldberg</a>
      <h6>Princeton University</h6>
    </div>
  </div>
  <div class="col-xs-6 col-lg-4">
    <a href="https://miriamhavin.wixsite.com/interactlab/blank-3">
      <img class="people-pic" src="https://media.licdn.com/dms/image/C4E03AQEBe4RlgFwcxQ/profile-displayphoto-shrink_800_800/0/1659734482819?e=2147483647&v=beta&t=SvngEkx4mUVw3YcU77Ue3gP7Ncd1nc-uA414_0MNtnY">
    </a>
    <div class="people-name">
      <a href="https://miriamhavin.wixsite.com/interactlab/blank-3">Ariel Goldstein</a>
      <h6>Hebrew University</h6>
    </div>
  </div>
  <div class="col-xs-6 col-lg-4">
    <a href="https://www.cs.utexas.edu/~huth/">
      <img class="people-pic" src="https://apps.jsg.utexas.edu/profiles/files/photos/alexander_huth_7939.jpg">
    </a>
    <div class="people-name">
      <a href="https://www.cs.utexas.edu/~huth/">Alex Huth</a>
      <h6>UT Austin</h6>
    </div>
  </div>
  <div class="col-xs-6 col-lg-4">
    <a href="https://anna-ivanova.net/">
      <img class="people-pic" src="https://anna-ivanova.net/authors/admin/avatar_huac969c89d5ddcf24f945bfdcc1546a2d_3098113_270x270_fill_q75_lanczos_center.jpg">
    </a>
    <div class="people-name">
      <a href="https://anna-ivanova.net/">Anna Ivanova</a>
      <h6>Georgia Tech</h6>
    </div>
  </div>
  <div class="col-xs-6 col-lg-4">
    <a href="https://najoung.kim/">
      <img class="people-pic" src="https://pbs.twimg.com/profile_images/1458194786117115907/SEpjgHUb_400x400.jpg">
    </a>
    <div class="people-name">
      <a href="https://najoung.kim/">Najoung Kim</a>
      <h6>Boston University</h6>
    </div>
  </div>
  <div class="col-xs-6 col-lg-4">
    <a href="https://www.mit.edu/~rplevy/">
      <img class="people-pic" src="https://bcs.mit.edu/sites/default/files/user-pics/Levy%2C%20Robert%20160114%20color%20resized.jpg">
    </a>
    <div class="people-name">
      <a href="https://www.mit.edu/~rplevy/">Roger Levy</a>
      <h6>MIT</h6>
    </div>
  </div>
  <div class="col-xs-6 col-lg-4">
    <a href="https://nlp.stanford.edu/~manning/">
      <img class="people-pic" src="https://nlp.stanford.edu/~manning/images/Christopher_Manning_027_1154x1154.jpg">
    </a>
    <div class="people-name">
      <a href="https://nlp.stanford.edu/~manning/">Christopher Manning</a>
      <h6>Stanford University</h6>
    </div>
  </div>
  <div class="col-xs-6 col-lg-4">
    <a href="https://rtmccoy.com/">
      <img class="people-pic" src="https://pbs.twimg.com/profile_images/1071805675100143616/nesJ5YNM_400x400.jpg">
    </a>
    <div class="people-name">
      <a href="https://rtmccoy.com/">Tom McCoy</a>
      <h6>Yale University</h6>
    </div>
  </div>
  <div class="col-xs-6 col-lg-4">
    <a href="https://www.cs.cmu.edu/~lwehbe/">
      <img class="people-pic" src="https://www.cmu.edu/ni/images/people-images/faculty-photos/lwehbe.jpg">
    </a>
    <div class="people-name">
      <a href="https://www.cs.cmu.edu/~lwehbe/">Leila Wehbe</a>
      <h6>Carnegie Mellon</h6>
    </div>
  </div>
  <div class="col-xs-6 col-lg-4">
    <a href="https://ai.meta.com/people/1396973444287406/adina-williams/">
      <img class="people-pic" src="https://media.licdn.com/dms/image/C4D03AQFFk9Vwb-EtDA/profile-displayphoto-shrink_800_800/0/1538586786275?e=2147483647&v=beta&t=0jZ1ty7fAcQNwEelvGinfSooKRdahsV_h-XFDcV1xkM">
    </a>
    <div class="people-name">
      <a href="https://ai.meta.com/people/1396973444287406/adina-williams/">Adina Williams</a>
      <h6>Meta AI</h6>
    </div>
  </div>
</div>

<hr />

<!-- Commentators -->
<div class="row" id="commentators">
  <div class="col-xs-12">
    <h2>Commentators</h2>
  </div>
</div>

<br/>

<div class="row">
  <div class="col-xs-6 col-lg-4">
    <a href="https://cs.gmu.edu/~antonis/author/antonios-anastasopoulos/">
      <img class="people-pic" src="https://www.gmu.edu/sites/g/files/yyqcgq291/files/2023-09/Antonios-Anastasopoulos-1x1.jpg">
    </a>
    <div class="people-name">
      <a href="https://cs.gmu.edu/~antonis/author/antonios-anastasopoulos/">Antonios Anastasopoulos</a>
      <h6>George Mason</h6>
    </div>
  </div>
  <div class="col-xs-6 col-lg-4">
    <a href="https://ishita-dg.github.io/">
      <img class="people-pic" src="https://ishita-dg.github.io/scholar_photo.jpeg">
    </a>
    <div class="people-name">
      <a href="https://ishita-dg.github.io/">Ishita Dasgupta</a>
      <h6>DeepMind</h6>
    </div>
  </div>
  <!-- <div class="col-xs-6 col-lg-4">
    <a href="https://lti.cmu.edu/people/faculty/diab-mona.html">
      <img class="people-pic" src="https://scsdean.cs.cmu.edu/new-faculty/resources/2023/mona_diab1.jpeg">
    </a>
    <div class="people-name">
      <a href="https://lti.cmu.edu/people/faculty/diab-mona.html">Mona Diab</a>
      <h6>Carnegie Mellon</h6>
    </div>
  </div> -->
  <div class="col-xs-6 col-lg-4">
    <a href="https://staff.fnwi.uva.nl/r.fernandezrovira/">
      <img class="people-pic" src="https://staff.fnwi.uva.nl/r.fernandezrovira/web/raq-2022.png">
    </a>
    <div class="people-name">
      <a href="https://staff.fnwi.uva.nl/r.fernandezrovira/">Raquel Fernández</a>
      <h6>University of Amsterdam</h6>
    </div>
  </div>
  <div class="col-xs-6 col-lg-4">
    <a href="https://lauragwilliams.github.io/">
      <img class="people-pic" src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcT_w5qDpIPiD2JPWmKkefuTOukD1EPLyjDlOGkKezZZiA&s">
    </a>
    <div class="people-name">
      <a href="https://lauragwilliams.github.io/">Laura Gwilliams</a>
      <h6>Stanford University</h6>
    </div>
  </div>
  <div class="col-xs-6 col-lg-4">
    <a href="https://mahowak.github.io/">
      <img class="people-pic" src="https://mahowak.github.io/assets/img/kylefogo2.png">
    </a>
    <div class="people-name">
      <a href="https://mahowak.github.io/">Kyle Mahowald</a>
      <h6>UT Austin</h6>
    </div>
  </div>
  <div class="col-xs-6 col-lg-4">
    <a href="https://tallinzen.net/">
      <img class="people-pic" src="https://pbs.twimg.com/profile_images/1774996720985784320/j936cGwU_400x400.jpg">
    </a>
    <div class="people-name">
      <a href="https://tallinzen.net/">Tal Linzen</a>
      <h6>NYU</h6>
    </div>
  </div>
  <div class="col-xs-6 col-lg-4">
    <a href="https://annargrs.github.io/">
      <img class="people-pic" src="https://annargrs.github.io/assets/images/aro.jpg">
    </a>
    <div class="people-name">
      <a href="https://annargrs.github.io/">Anna Rogers</a>
      <h6>IT University of Copenhagen</h6>
    </div>
  </div>
  <div class="col-xs-6 col-lg-4">
    <a href="https://psych.wisc.edu/staff/rogers-timothy-t/">
      <img class="people-pic" src="https://psych.wisc.edu/Rogers/tim1.jpg">
    </a>
    <div class="people-name">
      <a href="https://psych.wisc.edu/staff/rogers-timothy-t/">Timothy Rogers</a>
      <h6>University of Wisconsin</h6>
    </div>
  </div>
  <div class="col-xs-6 col-lg-4">
    <a href="http://languagestats.com/jonwillits/about.html">
      <img class="people-pic" src="https://media.licdn.com/dms/image/C5603AQGglKakTJu-uw/profile-displayphoto-shrink_200_200/0/1532384550390?e=2147483647&v=beta&t=vUITuFN-dwNUwbOxHdjXuquuq0VBLgcfmXgOsiRyGXU">
    </a>
    <div class="people-name">
      <a href="http://languagestats.com/jonwillits/about.html">Jon Willits</a>
      <h6>University of Illinois</h6>
    </div>
  </div>
</div>

<hr />

<!-- Organizers -->
<div class="row" id="organizers">
  <div class="col-xs-12">
    <h2>Organizing Team</h2>
  </div>
</div>

<br/>

<div class="row">
  <div class="col-xs-6 col-lg-3">
    <a href="https://cogandbrainlab.web.illinois.edu/">
      <img class="people-pic" src="https://i1.rgstatic.net/ii/profile.image/272344027496493-1441943284877_Q512/Kara-Federmeier.jpg">
    </a>
    <div class="people-name">
      <a href="https://cogandbrainlab.web.illinois.edu/">Kara Federmeier</a>
      <h6>University of Illinois</h6>
    </div>
  </div>
  <div class="col-xs-6 col-lg-3">
    <a href="https://www.mit.edu/~rplevy/">
      <img class="people-pic" src="https://bcs.mit.edu/sites/default/files/user-pics/Levy%2C%20Robert%20160114%20color%20resized.jpg">
    </a>
    <div class="people-name">
      <a href="https://www.mit.edu/~rplevy/">Roger Levy</a>
      <h6>MIT</h6>
    </div>
  </div>
  <div class="col-xs-6 col-lg-3">
    <a href="https://nlp.stanford.edu/~manning/">
      <img class="people-pic" src="https://nlp.stanford.edu/~manning/images/Christopher_Manning_027_1154x1154.jpg">
    </a>
    <div class="people-name">
      <a href="https://nlp.stanford.edu/~manning/">Christopher Manning</a>
      <h6>Stanford University</h6>
    </div>
  </div>
  <div class="col-xs-6 col-lg-3">
    <a href="https://benlipkin.github.io/">
      <img class="people-pic" src="https://avatars.githubusercontent.com/u/38060297?v=4">
    </a>
    <div class="people-name">
      <a href="https://benlipkin.github.io/">Benjamin Lipkin</a>
      <h6>MIT (Student Liaison)</h6>
    </div>
  </div>
</div>

<hr />

<!-- Motivation -->
<div class="row" id="motivation">
  <div class="col-xs-12">
    <h2>Motivation</h2>
  </div>
</div>

<br/>

<div class="row">
  <div class="col-xs-12">
    <p>
    This is a workshop dedicated to interdisciplinary connections
    between today’s large language models, language structure, and
    language processing in the human mind and brain. The structure of
    language, and the mental and neural basis of how it is learned,
    understood, and produced, have been perennial central questions in
    linguistics, computer science, cognitive science, and
    neuroscience. Historically, it has been a major challenge to
    develop implemented computational models that can generate and
    process language in anything approaching a human-like manner.
    </p><p> In recent years, however, this situation has been
    transformed by the impressive success of modern deep-learning
    technology: relatively simple artificial neural network
    architectures, when coupled with large-scale natural language
    corpora and computational software and hardware for training
    massive models with billions to hundreds of billions of
    parameters, learn to generate complex text of remarkable fluency
    and even seem to exhibit numerous "emergent" behaviors such as the
    ability to rhyme, metaphorical language use, and certain types of
    common-sense reasoning. Contemporary large language models (LLMs)
    achieve these successes even though–or perhaps,
    <i>because</i>–their internal representations are high-dimensional
    numeric embedding vectors that superficially seem to be very
    unlike the symbolic, hierarchical grammatical representations
    traditionally used to describe linguistic structure. Despite this
    apparent difference, LLMs' context-based word predictions reflect
    complex aspects of linguistic structure and correlate with human
    behavioral responses, tree-structured grammatical representations
    of sentences can be decoded with surprising accuracy from LLMs'
    embeddings, and those embeddings can even be used to predict
    high-dimensional brain responses during real-time language
    comprehension.  </p><p> But language in LLMs is also very
    different from language in humans. LLMs' training data is not
    grounded in extra-linguistic sensory or social context; their
    inductive biases do not always reflect common features found
    across languages of the world; their interpretive strategies can
    be fooled by superficial features of linguistic inputs; their
    patterns in ambiguity management differ from humans; and their
    common-sense reasoning patterns are often unreliable and
    inconsistent. In some cases, symbolic approaches can still yield
    superior performance on their own or in tandem with LLMs. Overall,
    while LLMs constitute remarkable technological advances, there are
    strong reasons to believe that they offer far from a complete
    picture of language development and processing in the human mind
    and brain.  </p><p> Inspired by this state of affairs, this
    workshop offers interdisciplinary talks and discussion spanning
    the fields of machine learning & natural language processing,
    linguistics, neuroscience, and cognitive science.</p>
  </div>
</div>

<hr />

<!-- Abstracts -->
<div class="row" id="abstracts">
  <div class="col-xs-12">
    <h2>Abstracts</h2>
  </div>
</div>

<br/>

<div class="row">
  <div class="col-xs-12">
    <div id="bergen">
      <p><a href="https://pages.ucsd.edu/~bkbergen/">Benjamin Bergen</a>: Large Language Models as distributional baselines for human language processing research</p>
      <p>Cognitive and linguistic capacities are often explained as resulting from sources outside of language, such as innate predispositions or grounded, embodied, or situated learning. But Large Language Models now rival human performance in a variety of tasks that have been argued to derive from these external causes. This raises the question: what human experimental results require language-external explanations, and which are consistent with a distributional, statistical learning account? We consider several linguistic inference phenomena—relating to affordances, pronoun resolution, and false belief inference. In each case, we run both human participants and LLMs on the same task and ask how much of the variance in human behavior is explained by the LLMs. As it turns out, in all cases, human behavior is not fully explained by the LLMs. This entails that, at least for now, we need something that goes beyond statistical language learning to explain these aspects of human language processing. At the same time, the LLM predictions do explain some of the human variance in these tasks, which simultaneously suggests a need for tighter experimental controls and more restricted inference when attributing human behavior to potential causes. The talk will conclude by asking—but not answering—a number of questions, like what the right criteria are for an LLM that serves as a proxy for human statistical language learning. </p>
    </div>
    <br/>
    <div id="wehbe">
      <p><a href="https://www.cs.cmu.edu/~lwehbe/">Leila Wehbe</a>: Learning representations of complex meaning in the human brain</p>
      <p>It has become increasingly common to use representations extracted from modern language models to study language comprehension in the human brain. This approach often achieves accurate prediction of brain activity, often accounting for almost all the variance in the recordings that is not attributable to noise. However, better prediction performance doesn't always lead to better scientific interpretability. This talk presents some approaches for the difficult problem of making scientific inferences about how the brain represents high-level meaning. While these inferences are based on the powerful ability of today's language models to predict brain recordings, this talk also explores the limitations of these models and their divergence from brain activity recordings, suggesting some language phenomena that they process differently than humans.</p>
    </div>
    <br/>
    <div id="goldstein">
      <p><a href="https://miriamhavin.wixsite.com/interactlab/blank-3">Ariel Goldstein</a>: Deep Modeling as (more) than (just) cognitive framework</p>
      <p> In my presentation, I will explore the assertion that deep learning-based models are not mere black boxes but rather valid frameworks for articulating computational theories for cognition and their neural infrastructure. My focus will primarily be on the comprehension and production of natural speech, using naturalistic stimuli and unrestrained conversations. I will illustrate common principles shared between deep language models (text-based), deep multimodal models (text and audio-based), and the brain using the neural activity associated with speech. I will discuss the new light shed by adopting deep modeling of fundamental long-lasting issues in cognitive neuroscience.</p>
    </div>
    <br/>
    <div id="bau">
      <p><a href="https://baulab.info/">David Bau</a>: Locating neural functions and facts</p>
      <p>Can we locate knowledge within a neural language model? Within an artificial neural network we can see every step of a neural computation. We discuss how simple counterfactual interventions can trace the neural mechanisms underlying a transformer language model's factual predictions such as “Miles Davis plays the trumpet.” And then we use the same technique to trace a language model’s remarkable ability to generalize a function after seeing examples, revealing a concrete mechanism for composing functional tasks.</p>
    </div>
    <br/>
    <div id="mccoy">
      <p><a href="https://rtmccoy.com/">Tom McCoy</a>: Using insights from linguistics to understand and guide Large Language Models</p>
      <p>A central goal in linguistics is characterizing how human language works. In this talk, I will discuss how such characterizations can contribute to the development of large language models (LLMs). First, analyses from linguistics can be used as standards against which we can evaluate LLMs, helping us to understand these notoriously hard-to-understand systems. Second, analyses from linguistics can also be used as targets toward which we can guide LLMs through specialized training procedures, enabling the creation of models that learn faster and generalize more robustly. Thus, linguistics can help make language models both more interpretable and more controllable.</p>
    </div>
    <br/>
    <div id="kim">
      <p><a href="https://najoung.kim/">Najoung Kim</a>: Linguistic tests as unit tests for AI systems</p>
      <p>The models underlying current breakthroughs in AI use language as a core medium of problem solving as well as interfacing with humans. In this regard, (behavioral) tests that gauge the linguistic capacity of AI systems serve as unit tests---small, focused tests to verify expected system behavior---for the stability of the models' core. Then, the role of the study of human language is clear: it is critical in defining both the unit itself and the test target. It motivates a fundamentally different carving of the problem space compared to benchmarks targeting downstream tasks such as information-seeking QA or machine translation. For example, if models systematically struggle with negation, this will affect many downstream tasks in practice, but may not always be captured by the task-specific benchmarks. I will discuss two lines of work in this direction on compositional generalization and entity tracking, and show how the test outcomes can inform both synchronic and diachronic solutions in model development. In this discussion, I will additionally argue that the linguistic unit tests need not and should not be fully analogous to tests targeting humans because the goal of AI is not necessarily to build a model _of_ humans but is to build something useful.</p>
    </div>
    <br/>
    <div id="williams">
      <p><a href="https://ai.meta.com/people/1396973444287406/adina-williams/">Adina Williams</a>: The shifting landscape of LM evaluation</p>
      <p>Cognitive scientists have contributed extensively to the development of large language models in the past and the present. Most notably, they have performed essential data work, have devised methods for interpreting and explaining model behavior, and have created important model performance evaluations. Despite this, the growing productionization potential of language models is spurring a shift in the types of contributions cognitive scientists are positioned to make. This talk will describe what this state of affairs means for cognitive scientists focusing on LM evaluation, and point to opportunities for new kinds of collaborations between cognitive scientists and the developers of machine learning models. </p>
    </div>
    <br/>
    <div id="cotterell">
      <p><a href="https://rycolab.io/">Ryan Cotterell</a>: A formal perspective on language modeling</p>
      <p>Language models—especially the large ones—are all the rage. And, for what will surely be one of only a few times in history, my field, natural language processing, is the center of world attention. Indeed, there is nearly a daily stream of articles in the popular press on the most recent advances in language modeling technology. In contrast to most of these articles (and most other talks on the topic), this tutorial-style presentation is not about forward progress in the area. Instead, I am going to take a step back and ask simple questions about the nature of language modeling itself. We will start with the most basic of questions: From a mathematical perspective, what is a language model? Next, the talk will turn philosophical. With all the talk of artificial general intelligence, what can theory of computation bring to bear on the computational power of language models? The talk will conclude with a statement of several recent theorems proven by my research group, the highlight of which is that no Transformer-based language model is Turing complete and, thus, we should be careful about labeling such language models, e.g., GPT-4, as general-purpose reasoners. </p>
    </div>
    <br/>
    <div id="goldberg">
      <p><a href="https://psychology.princeton.edu/people/adele-goldberg">Adele Goldberg</a>: Compositionality in natural language and LLMs</p>
      <p>Today’s LLMs interpret and produce language without using abstract rules, and close attention to the complexity of natural languages suggests this may be more of a feature than a bug. Behavioral parallels between LLMs and human language highlight the statistical aspects of both systems, raise questions about representations and mechanisms, and beckon us toward a deeper understanding of creativity and compositionality.</p>
    </div>
    <br/>
    <div id="ivanova">
      <p><a href="https://anna-ivanova.net/">Anna Ivanova</a>: Dissociating language and thought in large language models</p>
      <p>Today’s large language models (LLMs) routinely generate coherent, grammatical and seemingly meaningful paragraphs of text. This achievement has led to speculation that LLMs have become “thinking machines”, capable of performing tasks that require reasoning and/or world knowledge. In this talk, I will introduce a distinction between formal competence—knowledge of linguistic rules and patterns—and functional competence—understanding and using language in the world. This distinction is grounded in human neuroscience, which shows that formal and functional competence recruit different brain mechanisms. I will show that the word-in-context prediction objective has allowed LLMs to essentially master formal linguistic competence; however, pretrained LLMs still lag behind at many aspects of functional linguistic competence, prompting engineers to adopt specialized fune-tuning techniques and/or couple LLMs with external modules. I will then turn to world knowledge, a capability where the formal/functional distinction is less clear-cut, and discuss our efforts to leverage both cognitive science and NLP to develop systematic ways to probe world knowledge in text-based LLMs. Overall, the formal/functional competence framework clarifies the discourse around LLMs, helps develop targeted evaluations of their capabilities, and suggests ways for developing better models of real-life language use.</p>
    </div>
    <br/>
    <div id="begus">
      <p><a href="https://gbegus.github.io/">Gasper Begus</a>: Interpretability techniques for scientific discovery</p>
      <p>Interpretability is the new frontier in AI research. Understanding how generative models learn and how they resemble or differ from humans can not only provide insights for the study of human language, but can also facilitate discovery of novel patterns in diverse fields. For this purpose, it is essential to both introspect LLMs that test the limits of neural computation as well as to develop deep neural models that learn more like human infants acquiring language. In this talk, I outline a more realistic model of human language acquisition and introduce two AI interpretability techniques for the two approaches. The first technique uses our custom-built models and finds a causal relationship between individual neurons and linguistically meaningful properties. The second technique uses metalinguistics as a window into LLM's capabilities. Using the proposed techniques, we can compare and evaluate artificial and biological neural processing of language. Additionally, I show that AI interpretability techniques can facilitate scientific discovery by uncovering previously unrecognized patterns in complex data types.</p>
    </div>
    <br/>
    <div id="huth">
      <p><a href="https://www.cs.utexas.edu/~huth/">Alex Huth</a>: Mapping and decoding language representations in human cortex</p>
      <p>Is it possible to read the content of human thought out using recordings of brain activity? We use non-invasive functional MRI and machine learning methods based on large language models to investigate the relationship between brain activity and the content of thought. The models and modeling techniques we have developed reveal complex spatial and temporal patterns of brain activity that relate to specific categories of linguistic information as well as representational timescales. We show that this information can be read out as language, even when the stimulus evoking it is from another modality. These results point to a future of neuroscience that strongly integrates modern neural network models.</p>
    </div>
    <br/>
  </div>
</div>

<hr />

<!-- NSF -->
<div class="row" id="nsf">
  <div class="col-xs-12">
    <p>With Support from the Linguistics, Robust Intelligence, and Science of Learning and Augmented Intelligence Programs at NSF. This event is part of a two workshop series supported by the NSF. Follow the link below to learn more about and watch the recordings of the <a href="https://www.isu-pacelab.org/workshop-ai-text-production">Workshop on AI Text Production</a>.</p>
  </div>
  <div class="col-xs-12">
    <center>
      <img src="../static/img/nsf.jpg" width="200" height="200">
    </center>
  </div>
</div>

<hr />
